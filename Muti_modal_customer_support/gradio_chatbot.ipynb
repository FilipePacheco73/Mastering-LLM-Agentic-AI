{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Connect to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPEN_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 OpenAI Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "\n",
    "    messages = [{'role': 'system', 'content': system_message}]\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({'role': 'user', 'content': user_message})\n",
    "        messages.append({'role': 'assistant', 'content': assistant_message})\n",
    "    messages.append({'role': 'user', 'content': message})\n",
    "    \n",
    "    print('History is:')\n",
    "    print(history)\n",
    "    print('And messages is:')\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    response = ''\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Gradio Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Basic Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filip\\GitHub\\Mastering-LLM-Agentic-AI\\venv\\Lib\\site-packages\\gradio\\components\\chatbot.py:290: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are an helpful assistant'}, {'role': 'user', 'content': 'Hi'}]\n",
      "History is:\n",
      "[['Hi', 'Hello! How can I assist you today?']]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are an helpful assistant'}, {'role': 'user', 'content': 'Hi'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Tell me who you are?'}]\n",
      "History is:\n",
      "[['Hi', 'Hello! How can I assist you today?'], ['Tell me who you are?', \"I'm an AI language model created by OpenAI. My purpose is to assist users by providing information, answering questions, and helping with various tasks related to language and communication. Is there something specific you would like to know or discuss?\"]]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are an helpful assistant'}, {'role': 'user', 'content': 'Hi'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Tell me who you are?'}, {'role': 'assistant', 'content': \"I'm an AI language model created by OpenAI. My purpose is to assist users by providing information, answering questions, and helping with various tasks related to language and communication. Is there something specific you would like to know or discuss?\"}, {'role': 'user', 'content': 'tell me about the sun'}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Constrained Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "\n",
    "    messages = [{'role': 'system', 'content': system_message}]\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({'role': 'user', 'content': user_message})\n",
    "        messages.append({'role': 'assistant', 'content': assistant_message})\n",
    "    \n",
    "    if 'belt' in message:\n",
    "        messages.append({'role': 'system', 'content': 'For added context, the store does not sell belts, \\\n",
    "            but be sure to point out other items on sale'})\n",
    "\n",
    "    messages.append({'role': 'user', 'content': message})\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    response = ''\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filip\\GitHub\\Mastering-LLM-Agentic-AI\\venv\\Lib\\site-packages\\gradio\\components\\chatbot.py:290: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
